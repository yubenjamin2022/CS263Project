{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BioASQ Dataset Exploration\n",
    "\n",
    "This notebook explores the rag-mini-bioasq dataset structure and provides visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/ravi/miniconda3/envs/python310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "text_corpus = load_dataset('rag-datasets/rag-mini-bioasq', \"text-corpus\")\n",
    "question_answer_passages = load_dataset('rag-datasets/rag-mini-bioasq', \"question-answer-passages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(question_answer_passages[\"test\"][i][\"id\"]==i for i in range(len(question_answer_passages[\"test\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Is Hirschsprung disease a mendelian or a multifactorial disorder?',\n",
       " 'answer': \"Coding sequence mutations in RET, GDNF, EDNRB, EDN3, and SOX10 are involved in the development of Hirschsprung disease. The majority of these genes was shown to be related to Mendelian syndromic forms of Hirschsprung's disease, whereas the non-Mendelian inheritance of sporadic non-syndromic Hirschsprung disease proved to be complex; involvement of multiple loci was demonstrated in a multiplicative model.\",\n",
       " 'relevant_passage_ids': '[20598273, 6650562, 15829955, 15617541, 23001136, 8896569, 21995290, 12239580, 15858239]',\n",
       " 'id': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answer_passages[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save passages and dictionaries\n",
    "# encode all passages with sentence-transformers/all-MiniLM-L6-v2\n",
    "# top-k retrieval with faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passage': 'New data on viruses isolated from patients with subacute thyroiditis de Quervain \\nare reported. Characteristic morphological, cytological, some physico-chemical \\nand biological features of the isolated viruses are described. A possible role \\nof these viruses in human and animal health disorders is discussed. The isolated \\nviruses remain unclassified so far.',\n",
       " 'id': 9797}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_corpus[\"passages\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40221/40221 [00:02<00:00, 19615.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "pid_to_passage = {}\n",
    "pid_to_idx = {}\n",
    "for i in tqdm(range(len(text_corpus[\"passages\"]))):\n",
    "    passage = text_corpus[\"passages\"][i][\"passage\"]\n",
    "    passage_id = text_corpus[\"passages\"][i][\"id\"]\n",
    "    pid_to_passage[passage_id] = passage\n",
    "    pid_to_idx[passage_id] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_pid = {v:k for k,v in pid_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1257/1257 [00:31<00:00, 39.57it/s] \n"
     ]
    }
   ],
   "source": [
    "passages_list = [pid_to_passage[pid] for pid in sorted(pid_to_passage.keys())]\n",
    "embeddings = model.encode(passages_list, show_progress_bar=True) # already normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_list = [qap[\"question\"] for qap in question_answer_passages[\"test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/148 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 148/148 [00:01<00:00, 112.06it/s]\n"
     ]
    }
   ],
   "source": [
    "question_embeddings = model.encode(questions_list, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "question_embeddings, embeddings = torch.from_numpy(question_embeddings).to(\"cuda\"), torch.from_numpy(embeddings).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40221])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(embeddings @ question_embeddings[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:00<00:00, 561.25it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "k = 20\n",
    "retrieved_passages = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(question_embeddings), batch_size)):\n",
    "        batch_question_embeddings = question_embeddings[i:i+batch_size]\n",
    "        passage_scores = batch_question_embeddings @ embeddings.T # shape (batch_size, num_passages)\n",
    "        topk_passage_scores, topk_passage_indices = torch.topk(passage_scores, k=k, dim=1) # shape (batch_size, k)\n",
    "        topk_passage_indices = topk_passage_indices.cpu().tolist()\n",
    "        for indices in topk_passage_indices:\n",
    "            retrieved_passages.append([idx_to_pid[idx] for idx in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics: precision, recall, mrr, ndcg at k=1,5,10,20\n",
    "import json\n",
    "def compute_metrics(retrieved_passages, question_answer_passages, k):\n",
    "    precision_at_k = []\n",
    "    recall_at_k = []\n",
    "    mrr_at_k = []\n",
    "    ndcg_at_k = []\n",
    "    \n",
    "    for i, qap in enumerate(question_answer_passages[\"test\"]):\n",
    "        relevant_pids = set(json.loads(qap[\"relevant_passage_ids\"]))\n",
    "        retrieved_pids = retrieved_passages[i][:k]\n",
    "        \n",
    "        # Precision@k\n",
    "        precision = len(set(retrieved_pids) & relevant_pids) / k\n",
    "        precision_at_k.append(precision)\n",
    "        \n",
    "        # Recall@k\n",
    "        recall = len(set(retrieved_pids) & relevant_pids) / len(relevant_pids) if relevant_pids else 0\n",
    "        recall_at_k.append(recall)\n",
    "        \n",
    "        # MRR@k\n",
    "        mrr = 0\n",
    "        for rank, pid in enumerate(retrieved_pids, start=1):\n",
    "            if pid in relevant_pids:\n",
    "                mrr = 1 / rank\n",
    "                break\n",
    "        mrr_at_k.append(mrr)\n",
    "        \n",
    "        # NDCG@k\n",
    "        dcg = 0\n",
    "        idcg = sum(1 / torch.log2(torch.tensor(i + 2)) for i in range(min(len(relevant_pids), k)))\n",
    "        for rank, pid in enumerate(retrieved_pids, start=1):\n",
    "            if pid in relevant_pids:\n",
    "                dcg += 1 / torch.log2(torch.tensor(rank + 1))\n",
    "        ndcg = dcg / idcg if idcg > 0 else 0\n",
    "        ndcg_at_k.append(ndcg)\n",
    "    \n",
    "    return {\n",
    "        \"precision\": sum(precision_at_k) / len(precision_at_k),\n",
    "        \"recall\": sum(recall_at_k) / len(recall_at_k),\n",
    "        \"mrr\": sum(mrr_at_k) / len(mrr_at_k),\n",
    "        \"ndcg\": sum(ndcg_at_k) / len(ndcg_at_k)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics at k=1: {'precision': 0.5596524687433778, 'recall': 0.13204025265349995, 'mrr': 0.5596524687433778, 'ndcg': tensor(0.5597)}\n",
      "Metrics at k=5: {'precision': 0.3802076711167698, 'recall': 0.2926906106714452, 'mrr': 0.6261213533940809, 'ndcg': tensor(0.4885)}\n",
      "Metrics at k=10: {'precision': 0.28436109345199984, 'recall': 0.37335606086672535, 'mrr': 0.6313573631755454, 'ndcg': tensor(0.4615)}\n",
      "Metrics at k=20: {'precision': 0.18544183089637167, 'recall': 0.43850747045641564, 'mrr': 0.6339913724707721, 'ndcg': tensor(0.4505)}\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 5, 10, 20]:\n",
    "    metrics = compute_metrics(retrieved_passages, question_answer_passages, k)\n",
    "    print(f\"Metrics at k={k}: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PURPOSE: The phenotypic manifestations of cerebral cavernous malformation \\ndisease caused by rare PDCD10 mutations have not been systematically examined, \\nand a mechanistic link to Rho kinase-mediated hyperpermeability, a potential \\ntherapeutic target, has not been established.\\nMETHODS: We analyzed PDCD10 small interfering RNA-treated endothelial cells for \\nstress fibers, Rho kinase activity, and permeability. Rho kinase activity was \\nassessed in cerebral cavernous malformation lesions. Brain permeability and \\ncerebral cavernous malformation lesion burden were quantified, and clinical \\nmanifestations were assessed in prospectively enrolled subjects with PDCD10 \\nmutations.\\nRESULTS: We determined that PDCD10 protein suppresses endothelial stress fibers, \\nRho kinase activity, and permeability in vitro. Pdcd10 heterozygous mice have \\ngreater lesion burden than other Ccm genotypes. We demonstrated robust Rho \\nkinase activity in murine and human cerebral cavernous malformation vasculature \\nand increased brain vascular permeability in humans with PDCD10 mutation. \\nClinical phenotype is exceptionally aggressive compared with the more common \\nKRIT1 and CCM2 familial and sporadic cerebral cavernous malformation, with \\ngreater lesion burden and more frequent hemorrhages earlier in life. We first \\nreport other phenotypic features, including scoliosis, cognitive disability, and \\nskin lesions, unrelated to lesion burden or bleeding.\\nCONCLUSION: These findings define a unique cerebral cavernous malformation \\ndisease with exceptional aggressiveness, and they inform preclinical therapeutic \\ntesting, clinical counseling, and the design of trials.Genet Med 17 3, 188-196.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pid_to_passage[25122144]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cerebral cavernous malformations (CCM) are vascular malformations, mostly \\nlocated in the central nervous system, which occur in 0.1-0.5% of the \\npopulation. They are characterized by abnormally enlarged and often leaking \\ncapillary cavities without intervening neural parenchyma. Some are clinically \\nsilent, whereas others cause seizures, intracerebral haemorrhage or focal \\nneurological deficits. These vascular malformations can arise sporadically or \\nmay be inherited as an autosomal dominant condition with incomplete penetrance. \\nAt least 45% of families affected with cerebral cavernous malformations harbour \\na mutation in Krev interaction trapped-1 (Krit1) gene (cerebral cavernous \\nmalformation gene-1, CCM1). This gene contains 16 coding exons which encode a \\n736-amino acid protein containing three ankyrin repeats and a FERM domain. \\nNeither the CCM1 pathogenetic mechanisms nor the function of the Krit1 protein \\nare understood so far, although several hypotheses have been inferred from the \\npredicted consequences of Krit1 mutations as well as from the identification of \\nKrit1 as a binding partner of Rap1A, ICAP1A and microtubules. Here, we report \\nthe identification of Krit1B, a novel Krit1 isoform characterized by the \\nalternative splicing of the 15th coding exon. We show that the Krit1B splice \\nisoform is widely expressed in mouse cell lines and tissues, whereas its \\nexpression is highly restricted in human. In addition, we developed a real-time \\nPCR strategy to accurately quantify the relative ratio of the two Krit1 \\nalternative transcripts in different tissues, demonstrating a Krit1B/Krit1A \\nratio up to 20% in mouse thymus, but significantly lower ratios in other \\ntissues. Bioinformatic analysis using exon/gene-prediction, comparative \\nalignment and structure analysis programs supported the existence of Krit1 \\nalternative transcripts lacking the 15th coding exon and showed that the \\nsplicing out of this exon occurs outside of potentially important Krit1 \\nstructural domains but in a region required for association with Rap1A, \\nsuggesting a subtle, yet important effect on the protein function. Our results \\nindicate that maintenance of a proper ratio between Krit1A and Krit1B could be \\nfunctionally relevant and suggest that the novel Krit1B isoform might expand our \\nunderstanding of the role of Krit1 in CCM1 pathogenesis.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pid_to_passage[14697511]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "# load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each question, concatenate top 5 retrieved passages and question, and feed into the model to generate answer. Compute BLEU score between generated answer and reference answer.\n",
    "max_passages = 3\n",
    "final_prompts = []\n",
    "for i, qap in enumerate(question_answer_passages[\"test\"]):\n",
    "    question = qap[\"question\"]\n",
    "    retrieved_pids = retrieved_passages[i][:max_passages]\n",
    "    retrieved_passages_text = [pid_to_passage[pid] for pid in retrieved_pids]\n",
    "    prompt = f\"Question: {question}\\n\\nRetrieved Passages:\\n\" + \"\\n\\n\".join(retrieved_passages_text) + \"\\n\\nAnswer:\"\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": prompt}],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=False # Switches between thinking and non-thinking modes. Default is True.\n",
    "    )\n",
    "    final_prompts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 4719 prompts to prompts.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "out_path = \"prompts.jsonl\"\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, p in enumerate(final_prompts):\n",
    "        f.write(json.dumps({\"id\": i, \"prompt\": p}, ensure_ascii=False) + \"\\n\")\n",
    "print(\"Wrote\", len(final_prompts), \"prompts to\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = \"generations.jsonl\"\n",
    "generated_answers = []\n",
    "with open(in_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        generated_answers.append(data[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in /data1/ravi/miniconda3/envs/python310/lib/python3.10/site-packages (from rouge) (1.17.0)\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4719it [00:07, 672.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# compute BLEU score, and ROUGE score between generated answers and reference answers\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "smooth = SmoothingFunction().method1\n",
    "\n",
    "from rouge import Rouge\n",
    "reference_answers = [qap[\"answer\"] for qap in question_answer_passages[\"test\"]]\n",
    "bleu_scores = []\n",
    "rouge = Rouge()\n",
    "rouge_scores = []\n",
    "for gen, ref in tqdm(zip(generated_answers, reference_answers)):\n",
    "    bleu = sentence_bleu([ref.split()], gen.split(), smoothing_function=smooth)\n",
    "    rouge_score = rouge.get_scores(gen, ref)[0]\n",
    "    bleu_scores.append(bleu)\n",
    "    rouge_scores.append(rouge_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score: 0.02865773123700818\n",
      "Average ROUGE scores: {'rouge-1': 0.21720454673906245, 'rouge-2': 0.06592800250512523, 'rouge-l': 0.19785764219765312}\n"
     ]
    }
   ],
   "source": [
    "# print average BLEU and ROUGE scores\n",
    "avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "avg_rouge = {\n",
    "    \"rouge-1\": sum(score[\"rouge-1\"][\"f\"] for score in rouge_scores) / len(rouge_scores),\n",
    "    \"rouge-2\": sum(score[\"rouge-2\"][\"f\"] for score in rouge_scores) / len(rouge_scores),\n",
    "    \"rouge-l\": sum(score[\"rouge-l\"][\"f\"] for score in rouge_scores) / len(rouge_scores),\n",
    "}\n",
    "print(f\"Average BLEU score: {avg_bleu}\")\n",
    "print(f\"Average ROUGE scores: {avg_rouge}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
