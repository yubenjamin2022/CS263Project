# BioASQ RAG Baseline Configuration

# Dataset settings
dataset:
  name: "rag-datasets/rag-mini-bioasq"
  split: "test"  # Use test split for evaluation
  max_samples: null  # Set to an integer to limit samples for debugging

# Retrieval settings
retrieval:
  # Dense retrieval embedding model
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
  # Alternative: "pritamdeka/S-PubMedBert-MS-MARCO" for biomedical domain
  
  # Number of passages to retrieve
  top_k: 5
  
  # Batch size for encoding
  batch_size: 32
  
  # Index settings
  use_faiss: true
  faiss_index_type: "flat"  # Options: "flat", "ivf"

# Generation settings (Local LLM)
generation:
  # Local model for answer generation
  # Options:
  #   - Qwen/Qwen2.5-0.5B-Instruct (~1GB RAM, fastest)
  #   - Qwen/Qwen2.5-1.5B-Instruct (~3GB RAM)
  #   - Qwen/Qwen2.5-3B-Instruct (~6GB RAM, best quality)
  #   - TinyLlama/TinyLlama-1.1B-Chat-v1.0 (~2GB RAM)
  model_name: "Qwen/Qwen2.5-0.5B-Instruct"
  
  # Generation parameters
  max_new_tokens: 256
  temperature: 0.7
  top_p: 0.9
  do_sample: true
  
  # Number of passages to include in context
  num_passages_for_generation: 3

# Evaluation settings
evaluation:
  # Retrieval metrics to compute
  retrieval_metrics:
    - "recall"
    - "precision"
    - "mrr"
  
  # k values for recall@k and precision@k
  k_values: [1, 3, 5, 10]
  
  # Generation metrics
  generation_metrics:
    - "bertscore"
    - "bleu"
  
  # BERTScore model
  bertscore_model: "microsoft/deberta-xlarge-mnli"

# Output settings
output:
  results_dir: "outputs"
  save_predictions: true
  save_retrieved_passages: true
